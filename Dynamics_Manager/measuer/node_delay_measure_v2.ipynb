{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Measure the latency matrix in parallal'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Measure the latency matrix in parallal'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pods already exist in the namespace. Skipping DaemonSet deployment.\n"
     ]
    }
   ],
   "source": [
    "'''Deploy cross-node communication measuring pods'''\n",
    "\n",
    "from kubernetes import client, config\n",
    "\n",
    "def check_pods_existence(namespace):\n",
    "    core_v1 = client.CoreV1Api()\n",
    "    try:\n",
    "        pods = core_v1.list_namespaced_pod(namespace=namespace)\n",
    "        return len(pods.items) > 0 # return True\n",
    "    except client.rest.ApiException as e:\n",
    "        print(f\"Exception when calling CoreV1Api->list_namespaced_pod: {e}\")\n",
    "        return False\n",
    "\n",
    "def deploy_latency_measurement_daemonset_if_needed():\n",
    "    namespace = 'measure-nodes'\n",
    "    ds_name = 'latency-measurement-ds'\n",
    "    \n",
    "    # Assuming config and apps_v1 have been defined as before\n",
    "    config.load_kube_config()\n",
    "    apps_v1 = client.AppsV1Api()\n",
    "\n",
    "    # Check if pods exist in the namespace\n",
    "    pods_exist = check_pods_existence(namespace)\n",
    "\n",
    "    # If no pods exist, deploy the DaemonSet\n",
    "    if not pods_exist:\n",
    "        # Define the body of the DaemonSet\n",
    "        ds_body = client.V1DaemonSet(\n",
    "            api_version=\"apps/v1\",\n",
    "            kind=\"DaemonSet\",\n",
    "            metadata=client.V1ObjectMeta(name=ds_name),\n",
    "            spec=client.V1DaemonSetSpec(\n",
    "                selector=client.V1LabelSelector(\n",
    "                    match_labels={\"app\": \"latency-measurement\"}\n",
    "                ),\n",
    "                template=client.V1PodTemplateSpec(\n",
    "                    metadata=client.V1ObjectMeta(labels={\"app\": \"latency-measurement\"}),\n",
    "                    spec=client.V1PodSpec(\n",
    "                        containers=[client.V1Container(\n",
    "                            name=\"latency-container\",\n",
    "                            image=\"curlimages/curl\",\n",
    "                            security_context=client.V1SecurityContext(\n",
    "                                capabilities=client.V1Capabilities(\n",
    "                                    add=[\"NET_RAW\"]  # Required for ping\n",
    "                                )\n",
    "                            )\n",
    "                        )],\n",
    "                        restart_policy=\"Always\"\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Deploy the DaemonSet\n",
    "        try:\n",
    "            apps_v1.create_namespaced_daemon_set(namespace=namespace, body=ds_body)\n",
    "            print(f\"Deployed DaemonSet {ds_name} in namespace {namespace}\")\n",
    "        except client.rest.ApiException as e:\n",
    "            print(f\"Exception when calling AppsV1Api->create_namespaced_daemon_set: {e}\")\n",
    "    else:\n",
    "        print(\"Pods already exist in the namespace. Skipping DaemonSet deployment.\")\n",
    "\n",
    "# Call the function to deploy the DaemonSet if needed\n",
    "deploy_latency_measurement_daemonset_if_needed()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency from source node k8s-worker-6 to target node k8s-worker-3: 3.5300000000000002 milliseconds\n",
      "Latency from source node k8s-worker-6 to target node k8s-worker-7: 10.57 milliseconds\n",
      "Latency from source node k8s-worker-6 to target node k8s-worker-5: 7.495 milliseconds\n",
      "Latency from source node k8s-worker-6 to target node k8s-worker-9: 18.540999999999997 milliseconds\n",
      "Latency from source node k8s-worker-3 to target node k8s-worker-6: 3.49 milliseconds\n",
      "Latency from source node k8s-worker-3 to target node k8s-worker-5: 10.534999999999998 milliseconds\n",
      "Latency from source node k8s-worker-3 to target node k8s-worker-9: 14.561 milliseconds\n",
      "Latency from source node k8s-worker-9 to target node k8s-worker-4: 13.597 milliseconds\n",
      "Latency from source node k8s-worker-3 to target node k8s-worker-7: 7.538 milliseconds\n",
      "Latency from source node k8s-worker-3 to target node k8s-worker-2: 15.655 milliseconds\n",
      "Latency from source node k8s-worker-3 to target node k8s-worker-8: 3.758 milliseconds\n",
      "Latency from source node k8s-worker-9 to target node k8s-worker-7: 13.523 milliseconds\n",
      "Latency from source node k8s-worker-3 to target node k8s-worker-1: 18.756999999999998 milliseconds\n",
      "Latency from source node k8s-worker-9 to target node k8s-worker-3: 14.475 milliseconds\n",
      "Latency from source node k8s-worker-9 to target node k8s-worker-6: 18.589000000000002 milliseconds\n",
      "Latency from source node k8s-worker-9 to target node k8s-worker-1: 9.537 milliseconds\n",
      "Latency from source node k8s-worker-3 to target node k8s-worker-4: 22.659 milliseconds\n",
      "Latency from source node k8s-worker-9 to target node k8s-worker-2: 6.5360000000000005 milliseconds\n",
      "Latency from source node k8s-worker-9 to target node k8s-worker-8: 11.773 milliseconds\n",
      "Latency from source node k8s-worker-9 to target node k8s-worker-5: 13.59 milliseconds\n",
      "Latency from source node k8s-worker-6 to target node k8s-worker-1: 7.529 milliseconds\n",
      "Latency from source node k8s-worker-6 to target node k8s-worker-2: 6.5360000000000005 milliseconds\n",
      "Latency from source node k8s-worker-6 to target node k8s-worker-4: 4.548 milliseconds\n",
      "Latency from source node k8s-worker-6 to target node k8s-worker-8: 12.985 milliseconds\n",
      "Latency from source node k8s-worker-7 to target node k8s-worker-3: 7.607 milliseconds\n",
      "Latency from source node k8s-worker-7 to target node k8s-worker-6: 10.498000000000001 milliseconds\n",
      "Latency from source node k8s-worker-7 to target node k8s-worker-1: 11.577 milliseconds\n",
      "Latency from source node k8s-worker-7 to target node k8s-worker-9: 13.574 milliseconds\n",
      "Latency from source node k8s-worker-7 to target node k8s-worker-5: 6.420999999999999 milliseconds\n",
      "Latency from source node k8s-worker-7 to target node k8s-worker-2: 8.529 milliseconds\n",
      "Latency from source node k8s-worker-7 to target node k8s-worker-8: 14.874 milliseconds\n",
      "Latency from source node k8s-worker-7 to target node k8s-worker-4: 10.442 milliseconds\n",
      "Latency from source node k8s-worker-5 to target node k8s-worker-3: 10.696000000000002 milliseconds\n",
      "Latency from source node k8s-worker-5 to target node k8s-worker-9: 13.643 milliseconds\n",
      "Latency from source node k8s-worker-5 to target node k8s-worker-6: 7.739 milliseconds\n",
      "Latency from source node k8s-worker-5 to target node k8s-worker-7: 6.34 milliseconds\n",
      "Latency from source node k8s-worker-5 to target node k8s-worker-1: 35.78 milliseconds\n",
      "Latency from source node k8s-worker-5 to target node k8s-worker-2: 32.766999999999996 milliseconds\n",
      "Latency from source node k8s-worker-5 to target node k8s-worker-8: 9.834000000000001 milliseconds\n",
      "Latency from source node k8s-worker-5 to target node k8s-worker-4: 17.468999999999998 milliseconds\n",
      "Latency from source node k8s-worker-14 to target node k8s-worker-3: 24.544 milliseconds\n",
      "Latency from source node k8s-worker-14 to target node k8s-worker-9: 19.775000000000002 milliseconds\n",
      "Latency from source node k8s-worker-14 to target node k8s-worker-6: 18.613 milliseconds\n",
      "Latency from source node k8s-worker-14 to target node k8s-worker-7: 20.532 milliseconds\n",
      "Latency from source node k8s-worker-14 to target node k8s-worker-1: 11.530000000000001 milliseconds\n",
      "Latency from source node k8s-worker-14 to target node k8s-worker-5: 23.522000000000002 milliseconds\n",
      "Latency from source node k8s-worker-14 to target node k8s-worker-11: 0.09000000000000001 milliseconds\n",
      "Latency from source node k8s-worker-14 to target node k8s-worker-2: 5.507 milliseconds\n",
      "Latency from source node k8s-worker-14 to target node k8s-worker-12: 0.082 milliseconds\n",
      "Latency from source node k8s-worker-14 to target node k8s-worker-15: 0.047 milliseconds\n",
      "Latency from source node k8s-worker-14 to target node k8s-worker-4: 9.495999999999999 milliseconds\n",
      "Latency from source node k8s-worker-14 to target node k8s-worker-8: 24.828 milliseconds\n",
      "Latency from source node k8s-worker-14 to target node k8s-worker-13: 0.08 milliseconds\n",
      "Latency from source node k8s-worker-14 to target node k8s-worker-10: 0.085 milliseconds\n",
      "Latency from source node k8s-worker-1 to target node k8s-worker-9: 9.781 milliseconds\n",
      "Latency from source node k8s-worker-1 to target node k8s-worker-3: 18.895 milliseconds\n",
      "Latency from source node k8s-worker-1 to target node k8s-worker-6: 7.721 milliseconds\n",
      "Latency from source node k8s-worker-1 to target node k8s-worker-7: 11.584000000000001 milliseconds\n",
      "Latency from source node k8s-worker-1 to target node k8s-worker-5: 35.821 milliseconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''As there are network jitter sometimes, means soemtimes sudden rise for a signle measurement:\n",
    "To sovle this measuring issue:\n",
    "(1) a easy and simple way to do is just the choose the lowest measured vaule to represent the latency \n",
    "between the measured node pair.\n",
    "(2) another way, that can do is to meaured more vaules (like meaure 20 times), and use the 80% percentile as\n",
    "the latency.\n",
    "\n",
    "'''\n",
    "\n",
    "from kubernetes import client, config, stream\n",
    "import concurrent.futures\n",
    "\n",
    "# Handle individual latency measurements between source and target pods.\n",
    "def measure_latency_from_source_to_target(v1, namespace, source_pod, target_pod):\n",
    "    source_pod_name = source_pod.metadata.name\n",
    "    source_pod_node_name = source_pod.spec.node_name\n",
    "    target_pod_ip = target_pod.status.pod_ip\n",
    "    target_pod_name = target_pod.metadata.name\n",
    "    target_pod_node_name = target_pod.spec.node_name\n",
    "    result = (source_pod_node_name, target_pod_node_name, None)\n",
    "\n",
    "    if source_pod_name != target_pod_name:\n",
    "        exec_command = ['curl', '-o', '/dev/null', '-s', '-w', '%{time_total}', f'http://{target_pod_ip}']\n",
    "        latencies = []\n",
    "        for _ in range(5):\n",
    "            try:\n",
    "                resp = stream.stream(v1.connect_get_namespaced_pod_exec,\n",
    "                                     source_pod_name,\n",
    "                                     namespace,\n",
    "                                     command=exec_command,\n",
    "                                     stderr=True,\n",
    "                                     stdin=False,\n",
    "                                     stdout=True,\n",
    "                                     tty=False)\n",
    "                latency = float(resp) * 1000  # Convert the measured seconds into milliseconds\n",
    "                latencies.append(latency)\n",
    "            except Exception as e:\n",
    "                print(f\"Error executing command in pod {source_pod_name}: {e}\")\n",
    "        \n",
    "        if latencies:\n",
    "            min_latency = min(latencies) #choose the lowest measured vaule to represent the latency\n",
    "            result = (source_pod_node_name, target_pod_node_name, min_latency)\n",
    "            print(f\"Latency from source node {source_pod_node_name} to target node {target_pod_node_name}: {min_latency} milliseconds\")\n",
    "        else:\n",
    "            result = (source_pod_node_name, target_pod_node_name, \"Error\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def measure_http_latency(namespace='measure-nodes'):\n",
    "    v1 = client.CoreV1Api()\n",
    "    pods = v1.list_namespaced_pod(namespace, label_selector=\"app=latency-measurement\").items\n",
    "    latency_results = {}\n",
    "    \n",
    "    # Run the latency measurement tasks concurrently\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for source_pod in pods:\n",
    "            for target_pod in pods:\n",
    "                futures.append(executor.submit(measure_latency_from_source_to_target, v1, namespace, source_pod, target_pod))\n",
    "        \n",
    "        # Aggregate the completed results into the latency_results dictionary\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            source_pod_node_name, target_pod_node_name, latency = future.result()\n",
    "            if source_pod_node_name not in latency_results:\n",
    "                latency_results[source_pod_node_name] = {}\n",
    "            latency_results[source_pod_node_name][target_pod_node_name] = latency\n",
    "\n",
    "    return latency_results\n",
    "\n",
    "# from kubernetes import client, config\n",
    "# import concurrent.futures\n",
    "\n",
    "# def get_uncordoned_nodes():\n",
    "#     \"\"\"Return a set of node names that are schedulable (not cordoned).\"\"\"\n",
    "#     v1 = client.CoreV1Api()\n",
    "#     nodes = v1.list_node().items\n",
    "#     return {n.metadata.name for n in nodes if not getattr(n.spec, \"unschedulable\", False)}\n",
    "\n",
    "# def measure_http_latency(namespace='measure-nodes'):\n",
    "#     config.load_kube_config()\n",
    "#     v1 = client.CoreV1Api()\n",
    "\n",
    "#     # 1️⃣ Get all pods in the target namespace\n",
    "#     pods = v1.list_namespaced_pod(namespace, label_selector=\"app=latency-measurement\").items\n",
    "\n",
    "#     # 2️⃣ Get schedulable (uncordoned) nodes\n",
    "#     uncordoned_nodes = get_uncordoned_nodes()\n",
    "\n",
    "#     # 3️⃣ Keep only pods that are on uncordoned nodes\n",
    "#     active_pods = [p for p in pods if p.spec.node_name in uncordoned_nodes]\n",
    "\n",
    "#     print(f\"[INFO] Found {len(active_pods)} latency pods on uncordoned nodes: {[p.spec.node_name for p in active_pods]}\")\n",
    "\n",
    "#     latency_results = {}\n",
    "\n",
    "#     # 4️⃣ Run latency measurement tasks concurrently\n",
    "#     with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "#         futures = []\n",
    "#         for source_pod in active_pods:\n",
    "#             for target_pod in active_pods:\n",
    "#                 futures.append(\n",
    "#                     executor.submit(measure_latency_from_source_to_target,\n",
    "#                                     v1, namespace, source_pod, target_pod)\n",
    "#                 )\n",
    "\n",
    "#         # 5️⃣ Collect results\n",
    "#         for future in concurrent.futures.as_completed(futures):\n",
    "#             try:\n",
    "#                 source_node, target_node, latency = future.result()\n",
    "#                 latency_results.setdefault(source_node, {})[target_node] = latency\n",
    "#             except Exception as e:\n",
    "#                 print(f\"[WARN] Measurement failed: {e}\")\n",
    "\n",
    "#     return latency_results\n",
    "\n",
    "\n",
    "# Call the function to measure latency after deploying the DaemonSet\n",
    "namespace = 'measure-nodes'\n",
    "# After the DaemonSet is ready, and the related pods are ready\n",
    "latency_results = measure_http_latency(namespace=namespace)\n",
    "print(latency_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the nested dictionary into a pandas DataFrame\n",
    "df = pd.DataFrame(latency_results)\n",
    "\n",
    "# Transpose the DataFrame to align the source and destination workers as per convention\n",
    "df = df.T\n",
    "\n",
    "# Fill diagonal with 0's for self-latency (optional, if desired for clarity)\n",
    "for worker in df.columns:\n",
    "    df.at[worker, worker] = 0\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Normalize node-node communication delay matrix'''\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Convert the  dictionary into a pandas DataFrame and transpose it\n",
    "df = pd.DataFrame(latency_results).T\n",
    "\n",
    "# Mapping old names to new names\n",
    "worker_node = {\n",
    "    'k8s-worker-1': 'node-1', 'k8s-worker-2': 'node-2', 'k8s-worker-3': 'node-3',\n",
    "    'k8s-worker-4': 'node-4', 'k8s-worker-5': 'node-5', 'k8s-worker-6': 'node-6',\n",
    "    'k8s-worker-7': 'node-7', 'k8s-worker-8': 'node-8', 'k8s-worker-9': 'node-9'\n",
    "}\n",
    "\n",
    "# Rename the columns and index according to the dictionary\n",
    "df.rename(columns=worker_node, index=worker_node, inplace=True)\n",
    "\n",
    "# Fill diagonal with 0's for self-latency (optional, if desired for clarity)\n",
    "for worker in df.columns:\n",
    "    df.at[worker, worker] = 0\n",
    "\n",
    "# Normalize the DataFrame\n",
    "max_latency = df.max().max()  # Find the maximum value in the DataFrame\n",
    "normalized_df = df / max_latency  # Divide every element by the maximum value\n",
    "\n",
    "# Plot the normalized matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(normalized_df, annot=True,  cmap= \"Reds\",fmt=\".2f\", annot_kws={'size': 12},xticklabels=True, yticklabels=True, linewidths=.5)\n",
    "# plt.title('Normalized Latency Matrix')\n",
    "plt.xlabel('Destination Nodes', fontsize=15)\n",
    "plt.ylabel('Source Nodes', fontsize=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# k8s-worker --- node\n",
    "woker_node = {'k8s-worker-1': 'node1', 'k8s-worker-2': 'node2', 'k8s-worker-3': 'node3',\n",
    "              'k8s-worker-4': 'node4', 'k8s-worker-5': 'node5', 'k8s-worker-6': 'node6',\n",
    "              'k8s-worker-7': 'node7', 'k8s-worker-8': 'node8', 'k8s-worker-9': 'node9'}\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(latency_results).T\n",
    "for worker in df.columns:\n",
    "    df.at[worker, worker] = 0\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Invert the correlation matrix\n",
    "# inverted_corr_matrix =  np.abs(corr_matrix)\n",
    "\n",
    "# Plot the inverted correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Inverted Correlation Matrix')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the nested dictionary into a pandas DataFrame and transpose it\n",
    "df = pd.DataFrame(latency_results).T\n",
    "\n",
    "# Fill diagonal with 0's for self-latency\n",
    "for worker in df.columns:\n",
    "    df.at[worker, worker] = 0\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Dictionary to map old worker names to new names\n",
    "worker_node = {\n",
    "    'k8s-worker-1': 'node-1', 'k8s-worker-2': 'node-2', 'k8s-worker-3': 'node-3',\n",
    "    'k8s-worker-4': 'node-4', 'k8s-worker-5': 'node-5', 'k8s-worker-6': 'node-6',\n",
    "    'k8s-worker-7': 'node-7', 'k8s-worker-8': 'node-8', 'k8s-worker-9': 'node-9'\n",
    "}\n",
    "\n",
    "# Rename the columns and index of the correlation matrix for visualization\n",
    "renamed_corr_matrix = corr_matrix.rename(columns=worker_node, index=worker_node)\n",
    "\n",
    "# Take the absolute value of the correlation matrix to invert it\n",
    "inverted_renamed_corr_matrix = np.abs(renamed_corr_matrix)\n",
    "\n",
    "# Plot the inverted correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(inverted_renamed_corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", xticklabels=worker_node.values(), yticklabels=worker_node.values())\n",
    "plt.title('Inverted Correlation Matrix with Node Labels')\n",
    "plt.xlabel('Node')\n",
    "plt.ylabel('Node')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
